{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the website is always changing, the scraped properties will be different from ours when running our codes now. Consequently, all the results produced by running our codes now will be different from our results. Hence, we also uploaded notebooks which illustrate the codes and results we had gotten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The assumend granularity of region in our report is postcode, because it can be efficiently derived from the scraped name of properties and it is the smallest area that we could efficiently carry out our further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Website scraping and downlaoding external datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes for this part are included in the notebook scrape.ipynb and download.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties from the Domain website (https://www.domain.com.au/) were scraped using different sorting filters including properties with 1 bedroom, 2 bedrooms, 3 bedrooms, 4 bedrooms, 5+ bedrooms, featured properties, newest properties, lowest priced properties and highest priced properties. The original features scraped from each property included: property address (including postcode), advertised price, property coordinates, list of rooms (number of bedrooms, bathrooms, parking space), description of property, available date, property type (house, apartment, etc.) and a list containing distance(s) to the nearest school(s).\n",
    "\n",
    "8012 raw property instances were initially downloaded.\n",
    "\n",
    "Limitations:\n",
    "- Limited amount of data on properties were scraped, which is not a good representation of property prices in each postcode. I.e. some postcodes contained only single instances of property price.\n",
    "\n",
    "- Bias in property data from the search filters (e.g. highest priced properties).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance calculating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes for this part are included in the notebook proximity.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to calculate the distance of each property to the closest train station and to CBD (in meters) as two external features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to train stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of train station were derived by merging two external datasets from DATA VIC which include all the metropolitan and regional train station in Victoria (Annual_metropolitan_train_station_entries_2020-21.xlsx and Annual_regional_train_station_entries_2020-21.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to imrpove the efficiency, we decided to use K-NN clustering setting K=2 to find the 2 geometrically closetest train station to each property in the read in dataset, and then find the closest distance by car out of the two selected stations using Open route services api. The reason of setting K=2 is that it performs much better by K=1 (find smaller distace) and is much faster to implement than K=3. API keys are stored in text files in our local computer to ensure the security. \n",
    "\n",
    "Limitations:\n",
    "- The closest train station by car may not have been one of the two nearest neighbors calculated using Manhattan distancing\n",
    "- The amount of API requests were limited to 2000 a day which delayed the distance calculations for CBD and Train stations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to CBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance by car to CBD from each property was again calculated using the Open Route Services API. Api keys are stored in text files in our local computer to ensure the security.\n",
    "\n",
    "Limitations:\n",
    "- The amount of API requests were limited to 2000 a day which delayed the distance calculations for CBD and Train stations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population and income prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes and results for this part are included in the notebook population_prediction.ipynb and income_prediction.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population and average yearly income per person are the other two external features. Those information was derived from the two external datasets which are population_2001-21.xlsx and ABSIncomeSA2.xlsx from Australian Burean of Statistics. However, as those two external datasets do not include data of current year, we just assumed that our predicted data of current is accurate and would be used as the training data of the prediction model (but is actually inaccurate). The final datasets containing the predicted next 3 years' population and median income were stored as csv files in curated folder with the name population_prediction.csv and income_prediction.csv respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula used to predict population and income for the next 3 years:\n",
    "$P{next}=P{curr}\\times(1+\\frac{P{curr}-P{prev}}{P{prev}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use the same formula to predict next 3 years' population and median income, each year's growth rate for population and median income will be same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codes of this part are included in the notebook preprocess.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Basic preprocess was implemented to each property dataset and then merged all the datasets to be one final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, properties which do not provide information about the numbers of rooms and price were removed. Secondly, only useful features were selected. Then regular expression was used to derive postcodes from scraped names of properteis and to derive the numerical value of numbers of rooms, the distances to closest school and the prices of properties. Then the distances of each property to the closest train station and to CBD, which were stored in text files, were merged with the properties datasets. After the previous preprocess, all the properteis datasets were merged into one dataset removing all duplicate properties. This merged dataset contains 6754 properties in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the data of population and income were merged with the merged properteies dataset. As the data of population and income are in the granularity of SA2, we had to convert the granularity to postcode. The conversion was done by: for population, we decided to divide the whole population of an SA2 area to each postcode which belongs to that SA2 by the proportion of number of the properties in each postcode area; for income, we assumed that all the postcodes belong to one SA2 area have the same income data as that SA2 area; for postcodes which belong to multiple SA2 areas, we just added up the population and income of each SA2 area. However, it is obvious that inevitable inaccuracy was created by the process of conversion. \n",
    "Finally, the features in the final dataset are name, postcode, property_type, number of bedrooms, number of bathrooms, number of parking spaces, price, distance to the nearest train station (in meters), distance to CBD (in meters), distance to the nearest school (in km), population and income in current year, in 2023, in 2024 and in 2025. Then the final dataset was stored as a csv file in the curated folder with the name final2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes for this part are included in the notebook price_normalization.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we assumed properties with rental price < $100 and > $100000 to be outliers and remove them.\n",
    "Using K-means clustering from Sklearn, the prices where assigned to 4 separate clusters. One cluster was assumed to be the monthly price, another was assumed to be the annual price and the remaining two were assumed to be weekly prices (upper and lower end). Using these cluster labels and another assumption that monthly prices were within $2000 and $20000 and annual prices exceeded $20000, property prices were then standardized to price per week.\n",
    "\n",
    "Limitations:\n",
    "- Misclassification of price granularity using K-means clustering as there may have been price overlaps in clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, postcode areas with population < 100 and average yearly income per person < $1000 and properties with 0 bedrooms were assumed as outliers which could affect the performance of feature selection and prediction mode. We removed them before further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes and results for this part are included in the notebook feature selection（Anova test).ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anova was implemented to determine if each internal and external variables has significant influence on rental price. And we stored the output of Anova in the curated folder with the name feature_selection.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C(property_type)</td>\n",
       "      <td>4.004823e+06</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.637327</td>\n",
       "      <td>1.354623e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(bedrooms)</td>\n",
       "      <td>2.539828e+07</td>\n",
       "      <td>11.0</td>\n",
       "      <td>53.573437</td>\n",
       "      <td>4.080512e-114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(bathrooms)</td>\n",
       "      <td>3.151468e+07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81.247174</td>\n",
       "      <td>1.217086e-143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(parking)</td>\n",
       "      <td>2.815069e+06</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.024393</td>\n",
       "      <td>6.448718e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schools</td>\n",
       "      <td>1.110345e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.762971</td>\n",
       "      <td>3.964761e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_station</td>\n",
       "      <td>1.017019e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.975557</td>\n",
       "      <td>2.320107e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBD</td>\n",
       "      <td>2.228292e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>517.023168</td>\n",
       "      <td>2.689856e-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>population2022</td>\n",
       "      <td>4.878717e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.199226</td>\n",
       "      <td>3.164387e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>income2022</td>\n",
       "      <td>7.001461e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.245256</td>\n",
       "      <td>5.626814e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Residual</td>\n",
       "      <td>2.874239e+08</td>\n",
       "      <td>6669.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        sum_sq      df           F         PR(>F)\n",
       "0  C(property_type)  4.004823e+06    14.0    6.637327   1.354623e-13\n",
       "1       C(bedrooms)  2.539828e+07    11.0   53.573437  4.080512e-114\n",
       "2      C(bathrooms)  3.151468e+07     9.0   81.247174  1.217086e-143\n",
       "3        C(parking)  2.815069e+06    13.0    5.024393   6.448718e-09\n",
       "4           schools  1.110345e+06     1.0   25.762971   3.964761e-07\n",
       "5     train_station  1.017019e+07     1.0  235.975557   2.320107e-52\n",
       "6               CBD  2.228292e+07     1.0  517.023168  2.689856e-110\n",
       "7    population2022  4.878717e+06     1.0  113.199226   3.164387e-26\n",
       "8        income2022  7.001461e+05     1.0   16.245256   5.626814e-05\n",
       "9          Residual  2.874239e+08  6669.0         NaN            NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Anova output file\n",
    "import pandas as pd\n",
    "df_feature_selection = pd.read_csv(\"./data/curated/feature_selection.csv\")\n",
    "df_feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table is the output of using Anova for feature selection. From the last column of the table, it can found that the p-value of all internal and external features are less than 0.05, which means all features have significant influence on rental price.\n",
    "Hence, we concluded that useful internal features:property type, number of bedrooms, number of bathrooms, number of parking; useful external features: distance to the nearest school, distance to the nearest train station, distance to CBD, population, median income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/curated/price_normalised3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/User/Desktop/Sem2 2022/Applied Data Science/Project 2/generic-real-estate-consulting-project-group-9/summary.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/User/Desktop/Sem2%202022/Applied%20Data%20Science/Project%202/generic-real-estate-consulting-project-group-9/summary.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/User/Desktop/Sem2%202022/Applied%20Data%20Science/Project%202/generic-real-estate-consulting-project-group-9/summary.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/User/Desktop/Sem2%202022/Applied%20Data%20Science/Project%202/generic-real-estate-consulting-project-group-9/summary.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df5 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/curated/price_normalised3.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/User/Desktop/Sem2%202022/Applied%20Data%20Science/Project%202/generic-real-estate-consulting-project-group-9/summary.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/User/Desktop/Sem2%202022/Applied%20Data%20Science/Project%202/generic-real-estate-consulting-project-group-9/summary.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m sns\u001b[39m.\u001b[39mboxplot( \u001b[39m'\u001b[39m\u001b[39mcost_text\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mproperty_type\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mdf5, ax\u001b[39m=\u001b[39max, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/curated/price_normalised3.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df5 = pd.read_csv(\"../data/curated/price_normalised3.csv\")\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.boxplot( 'cost_text', 'property_type', data=df5, ax=ax, orient='h')\n",
    "plt.title('boxplot by property type')\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.yticks(rotation=90)\n",
    "plt.rc('font', size=15)\n",
    "plt.savefig('../plots/boxplot2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above codes produce a boxplot of prices of properties by each property type. From the boxplot (our boxplot is included in the boxplot.ipynb), it can be seen that the feature property_type does have an impact on prices of properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction model and model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes and results for this part are included in the notebook model.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model of prediction, we decided to use neural network as it is quite useful for regression of non-linear correlation with hidden layers. The neural network we decided to built has 2 (avoid over-fitting) hidden layers both having 12 neurons and using Rectified Linear Unit (ReLU) function as the activation function. The ouput layer has only one neuron and linear function as activation function because our aim of the model is regression. There are nine selected features. However, after one-hot encoding the categorical feature property_type, 22 features in total are in the input layer of our neural network model. A graph illustrating the structure of our neural network model was also produced in model.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, standard scaler from sklearn was used to standardise training data, which significantly improved the performance of the prediction model. Adam was chosen to be the optimizer of the model. Mean squared error was chosen to be the loss function. R square was chosen to be a metrics. The model was trained using batch_size 64 and 197 epochs (we tried some different epochs and found 197 epochs was the best for us)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the final values of MAE (0.3852) and R2 (0.6209), we can say that performance of the model is acceptable and satisfactory to us. Moreover, a scatter plot of true prices vs predicted prices of properteis in the test dataset (which is 20% of the whole training dataset chosen randomly) was sketched to check performance. From our plot, the performance of the model can still be considered as acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction and calculate growth rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes and results for this part are also included in the notebook model.ipynb in the notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then used the model to predict future prices of 2025. However, there is an issue here which can affect the accuracy of the prediction. That is: after getting the standardized values of the predicted prices of 2025 using the model, inverse standardization of those values can be inaccurate because we don't have the real values of future prices and can only use the scaler calculated using the values of current prices for inverse standardization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Answers to the 3 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the most important internal and external features in predicting rental prices?\n",
    "Significant internal features： property type, number of bedrooms, bathrooms and parking \n",
    "Significant external features： distance to school, train station and CBD, population, income \n",
    "\n",
    "2. What are the top 10 suburbs with the highest predicted growth rate?\n",
    "Top Suburbs:\n",
    "3714 %227\n",
    "3779 %108\n",
    "3019 %79\n",
    "3075 %45\n",
    "3026 %41\n",
    "3047 %40\n",
    "3020 %36\n",
    "3048 %34\n",
    "3060 %32\n",
    "3038 %32\n",
    "\n",
    "3. What are the most liveable and affordable suburbs according to your chosen metrics?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
